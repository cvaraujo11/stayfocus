# Guia de Submiss√£o ao Google Search Console

## üìã Pr√©-requisitos

- [ ] Dom√≠nio configurado e em produ√ß√£o
- [ ] Vari√°vel `NEXT_PUBLIC_BASE_URL` configurada no `.env.local`
- [ ] Deploy realizado com sucesso

## üöÄ Passos para Configura√ß√£o

### 1. Acessar o Google Search Console

1. Acesse: https://search.google.com/search-console
2. Fa√ßa login com sua conta Google
3. Clique em "Adicionar propriedade"

### 2. Verificar Propriedade do Site

Escolha um dos m√©todos de verifica√ß√£o:

#### Op√ß√£o A: Verifica√ß√£o por arquivo HTML
1. Baixe o arquivo de verifica√ß√£o fornecido pelo Google
2. Coloque o arquivo na pasta `public/` do projeto
3. Fa√ßa deploy
4. Clique em "Verificar" no Google Search Console

#### Op√ß√£o B: Verifica√ß√£o por tag HTML
1. Copie a meta tag fornecida pelo Google
2. Adicione no `app/layout.tsx` dentro do `<head>`
3. Fa√ßa deploy
4. Clique em "Verificar" no Google Search Console

#### Op√ß√£o C: Verifica√ß√£o por DNS (Recomendado)
1. Copie o registro TXT fornecido pelo Google
2. Adicione no seu provedor de DNS
3. Aguarde propaga√ß√£o (pode levar at√© 48h)
4. Clique em "Verificar" no Google Search Console

### 3. Submeter Sitemap

1. No Google Search Console, v√° em "Sitemaps" no menu lateral
2. Digite: `sitemap.xml`
3. Clique em "Enviar"
4. Aguarde o Google processar (pode levar alguns dias)

### 4. Verificar Robots.txt

1. No Google Search Console, v√° em "Configura√ß√µes" > "Rastreadores"
2. Clique em "Testar robots.txt"
3. Verifique se as regras est√£o corretas
4. Teste URLs espec√≠ficas para confirmar bloqueio/permiss√£o

## üìä Monitoramento

Ap√≥s a configura√ß√£o, monitore regularmente:

- **Cobertura**: P√°ginas indexadas vs. exclu√≠das
- **Desempenho**: Cliques, impress√µes, CTR, posi√ß√£o m√©dia
- **Experi√™ncia**: Core Web Vitals, usabilidade mobile
- **Seguran√ßa**: Problemas de seguran√ßa detectados

## üîß Arquivos Criados

### `/public/robots.txt`
Arquivo est√°tico que define regras de rastreamento para bots.

### `/app/robots.ts`
Gerador din√¢mico de robots.txt (Next.js App Router).
- Usa `NEXT_PUBLIC_BASE_URL` para URL do sitemap
- Bloqueia rotas privadas automaticamente

### `/app/sitemap.ts`
Gerador din√¢mico de sitemap.xml (Next.js App Router).
- Atualiza automaticamente a cada build
- Inclui apenas rotas p√∫blicas
- Define prioridades e frequ√™ncias de atualiza√ß√£o

## üåê URLs Geradas

Ap√≥s o deploy, os seguintes endpoints estar√£o dispon√≠veis:

- `https://seu-dominio.com/robots.txt`
- `https://seu-dominio.com/sitemap.xml`

## ‚öôÔ∏è Configura√ß√£o de Ambiente

Adicione no seu `.env.local`:

```env
NEXT_PUBLIC_BASE_URL=https://seu-dominio.com
```

**Importante**: Substitua `seu-dominio.com` pela URL real do seu site em produ√ß√£o.

## üîÑ Atualiza√ß√µes Futuras

### Adicionar novas rotas p√∫blicas

Edite `app/sitemap.ts` e adicione a nova rota no array:

```typescript
{
  url: `${baseUrl}/nova-rota`,
  lastModified: currentDate,
  changeFrequency: 'weekly' as const,
  priority: 0.7,
}
```

### Bloquear novas rotas privadas

Edite `app/robots.ts` e adicione no array `disallow`:

```typescript
disallow: [
  // ... rotas existentes
  '/nova-rota-privada',
],
```

## üìö Recursos Adicionais

- [Documenta√ß√£o Next.js - Metadata](https://nextjs.org/docs/app/api-reference/file-conventions/metadata)
- [Google Search Console - Central de Ajuda](https://support.google.com/webmasters)
- [Robots.txt - Especifica√ß√£o](https://developers.google.com/search/docs/crawling-indexing/robots/intro)
- [Sitemaps - Protocolo](https://www.sitemaps.org/protocol.html)
